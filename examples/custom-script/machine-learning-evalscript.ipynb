{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and run a Machine Learning model as a custom-script\n",
    "\n",
    "This notebook showcases how to create a Machine Learning (ML) custom-script for water detection. The workflow uses [eo-learn](https://eo-learn.readthedocs.io/en/latest/) to process the data and [LightGBM](https://lightgbm.readthedocs.io/en/latest/) to train a ML model for water classification given Seninel-2 band and index values. The resulting custom-script can be used in [the Sentinel Hub EOBrowser](https://www-test.sentinel-hub.com/explore/eobrowser/), in the [multi-temporal instance of Sentinel Playground](https://apps.sentinel-hub.com/sentinel-playground-temporal/?source=S2&lat=40.4&lng=-3.730000000000018&zoom=12&preset=1-NATURAL-COLOR&layers=B04,B03,B02&maxcc=20&gain=1.0&temporal=true&gamma=1.0&time=2015-01-01%7C2019-10-02&atmFilter=&showDates=false) and as evalscript in the [Sentinel Hub process API](https://docs.sentinel-hub.com/api/latest/api/process/).\n",
    "\n",
    "The workflow is as follows:\n",
    "\n",
    " * download training and testing data\n",
    " * prepare samples for ML algorithm\n",
    " * train ML model\n",
    " * export trained model as custom-script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jupyter notebook related\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "# Built-in modules\n",
    "import urllib.request\n",
    "import shutil\n",
    "import zipfile\n",
    "\n",
    "# # Basics of Python data handling and visualization\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "# import matplotlib as mpl\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.gridspec as gridspec\n",
    "# from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "# from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "# from shapely.geometry import Polygon\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Machine learning \n",
    "from sklearn.cluster import DBSCAN\n",
    "import lightgbm as lgbm\n",
    "# import joblib\n",
    "from sklearn import metrics\n",
    "# from sklearn import preprocessing\n",
    "\n",
    "# # Imports from eo-learn and sentinelhub-py\n",
    "from eolearn.core import EOPatch, EOTask, LinearWorkflow, FeatureType, OverwritePermission, \\\n",
    "    LoadTask, SaveTask, EOExecutor, ExtractBandsTask, MergeFeatureTask\n",
    "from eolearn.features import NormalizedDifferenceIndexTask\n",
    "from eolearn.geometry import PointSamplingTask #, ErosionTask, VectorToRaster\n",
    "# from eolearn.io import SentinelHubInputTask, ExportToTiff\n",
    "# from eolearn.mask import AddMultiCloudMaskTask, AddValidDataMaskTask\n",
    "# from sentinelhub import UtmZoneSplitter, BBox, CRS, DataSource"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the data\n",
    "\n",
    "* used to improve the blue-bot observatory\n",
    "* collected with the Classification App\n",
    "* available on bucket\n",
    "* info on what they contain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up url and data paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_URL = 'http://queryplanet.sentinel-hub.com/water-labels'\n",
    "\n",
    "DATA_INFO = f'{DATA_URL}/data-info.geojson'\n",
    "EOP_URL = f'{DATA_URL}/eopatches.zip'\n",
    "\n",
    "EOP_ZIP = './eopatches.zip'\n",
    "EOP_DIR = '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "S2_BANDS = ['B01', 'B02', 'B03', 'B04', 'B05', 'B06', 'B07', 'B08', 'B8A', 'B09', 'B10', 'B11', 'B12']\n",
    "S2_BANDS_STR = ','.join(S2_BANDS)\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "TRAIN_RATIO = .8\n",
    "\n",
    "N_WORKERS = 4\n",
    "\n",
    "N_SAMPLES = 100\n",
    "REF_LABELS = [0, 1]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file(DATA_INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_DEM</th>\n",
       "      <th>has_S1_ASC</th>\n",
       "      <th>has_S1_DES</th>\n",
       "      <th>has_S2</th>\n",
       "      <th>task_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>window_height</th>\n",
       "      <th>window_width</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6b73fd74a2eb11e994fbf0db728b8d14</td>\n",
       "      <td>2016-09-26</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>POLYGON ((65.84065 52.68916, 65.84065 52.69491...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0a27f4aea2eb11e9bfdaa9140581204c</td>\n",
       "      <td>2017-08-12</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>POLYGON ((64.47018 50.95125, 64.47018 50.95701...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9b60193ea24111e98d7d929084d604de</td>\n",
       "      <td>2019-03-23</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>POLYGON ((31.15408 38.61106, 31.15408 38.61600...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9afaabaea24111e983d185262381d01a</td>\n",
       "      <td>2018-05-31</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>POLYGON ((-1.60285 38.21084, -1.60285 38.21558...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9dfb5254a24111e9a087737fe71fcff1</td>\n",
       "      <td>2018-05-27</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>POLYGON ((48.22342 48.99523, 48.22342 49.00099...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   has_DEM  has_S1_ASC  has_S1_DES  has_S2                           task_id  \\\n",
       "0        1           0           0       1  6b73fd74a2eb11e994fbf0db728b8d14   \n",
       "1        1           0           1       1  0a27f4aea2eb11e9bfdaa9140581204c   \n",
       "2        1           1           1       1  9b60193ea24111e98d7d929084d604de   \n",
       "3        1           1           1       1  9afaabaea24111e983d185262381d01a   \n",
       "4        1           0           1       1  9dfb5254a24111e9a087737fe71fcff1   \n",
       "\n",
       "    timestamp  window_height  window_width  \\\n",
       "0  2016-09-26             64            64   \n",
       "1  2017-08-12             64            64   \n",
       "2  2019-03-23             64            64   \n",
       "3  2018-05-31             64            64   \n",
       "4  2018-05-27             64            64   \n",
       "\n",
       "                                            geometry  \n",
       "0  POLYGON ((65.84065 52.68916, 65.84065 52.69491...  \n",
       "1  POLYGON ((64.47018 50.95125, 64.47018 50.95701...  \n",
       "2  POLYGON ((31.15408 38.61106, 31.15408 38.61600...  \n",
       "3  POLYGON ((-1.60285 38.21084, -1.60285 38.21558...  \n",
       "4  POLYGON ((48.22342 48.99523, 48.22342 49.00099...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7671, 7671)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gdf), len(gdf[gdf.has_S2==1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and unzip file with eopatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://queryplanet.sentinel-hub.com/water-labels/eopatches.zip to ./eopatches.zip ..\n",
      "Unzipping ./eopatches.zip to . ..\n"
     ]
    }
   ],
   "source": [
    "print(f'Downloading {EOP_URL} to {EOP_ZIP} ..')\n",
    "with urllib.request.urlopen(EOP_URL) as response, open(EOP_ZIP, 'wb') as zip_file:\n",
    "    shutil.copyfileobj(response, zip_file)\n",
    "    \n",
    "print(f'Unzipping {EOP_ZIP} to {EOP_DIR} ..')\n",
    "with zipfile.ZipFile(EOP_ZIP, 'r') as zip_file:\n",
    "    zip_file.extractall(EOP_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7672\r\n"
     ]
    }
   ],
   "source": [
    "ls -lth {EOP_DIR}/eopatches | wc -l "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up and run feature processing workflow with `eo-learn`\n",
    "\n",
    "* load eopatches\n",
    "* keep only B02, B03 and B04\n",
    "* add NDWI and NDMI\n",
    "* sample pixels\n",
    "* save sampled arrays only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build name of eopatches, given by index of `data_info`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "eopatch_names = [f'eopatch-{idx:04d}' for idx in np.arange(len(gdf))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load an eopathc and inspect content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EOPatch(\n",
       "  data: {\n",
       "    BANDS-S2-L1C: numpy.ndarray(shape=(1, 64, 64, 13), dtype=float32)\n",
       "    FEATURES_SAMPLED: numpy.ndarray(shape=(1, 100, 1, 5), dtype=float32)\n",
       "    TRUE-COLOR-S1-IW-DES: numpy.ndarray(shape=(1, 64, 64, 3), dtype=float32)\n",
       "  }\n",
       "  mask: {\n",
       "    IS_DATA: numpy.ndarray(shape=(1, 64, 64, 1), dtype=bool)\n",
       "    IS_DATA_S1_IW_DES: numpy.ndarray(shape=(1, 64, 64, 1), dtype=bool)\n",
       "    IS_DATA_SAMPLED: numpy.ndarray(shape=(1, 100, 1, 1), dtype=bool)\n",
       "  }\n",
       "  scalar: {}\n",
       "  label: {}\n",
       "  vector: {}\n",
       "  data_timeless: {\n",
       "    DEM: numpy.ndarray(shape=(64, 64, 1), dtype=float32)\n",
       "  }\n",
       "  mask_timeless: {\n",
       "    water_label: numpy.ndarray(shape=(64, 64, 1), dtype=uint8)\n",
       "    water_label_SAMPLED: numpy.ndarray(shape=(100, 1, 1), dtype=uint8)\n",
       "  }\n",
       "  scalar_timeless: {}\n",
       "  label_timeless: {}\n",
       "  vector_timeless: {}\n",
       "  meta_info: {\n",
       "    TRUE-COLOR-S1-IW-DES: datetime.timedelta(-2, 6658)\n",
       "    maxcc: 1.0\n",
       "    service_type: 'wms'\n",
       "    size_x: 64\n",
       "    size_y: 64\n",
       "    time_difference: datetime.timedelta(1)\n",
       "    time_interval: (datetime.datetime(2017, 8, 12, 0, 0), datetime.datetime(2017, 8, 13, 0, 0))\n",
       "    timestamp: '2017-08-12'\n",
       "  }\n",
       "  bbox: BBox(((64.47018117599022, 50.951253746594006), (64.47931440474328, 50.9570068827248)), crs=CRS('4326'))\n",
       "  timestamp: [datetime.datetime(2017, 8, 12, 6, 47, 48)]\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eop = EOPatch.load(f'{EOP_DIR}/eopatches/{eopatch_names[1]}')\n",
    "eop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "BANDS_FEATURE = FeatureType.DATA, 'BANDS-S2-L1C'\n",
    "IS_DATA_FEATURE = FeatureType.MASK, 'IS_DATA'\n",
    "\n",
    "BANDS_SUB_FEATURE = FeatureType.DATA, 'BANDS-SUBSET'\n",
    "NDWI_FEATURE = FeatureType.DATA, 'NDWI'\n",
    "NDMI_FEATURE = FeatureType.DATA, 'NDMI'\n",
    "\n",
    "FEATURES = FeatureType.DATA, 'FEATURES'\n",
    "\n",
    "LABELS = FeatureType.MASK_TIMELESS, 'water_label'\n",
    "\n",
    "FEATURES_SAMPLED = FeatureType.DATA, 'FEATURES_SAMPLED'\n",
    "IS_DATA_SAMPLED = FeatureType.MASK, 'IS_DATA_SAMPLED'\n",
    "LABELS_SAMPLED = FeatureType.MASK_TIMELESS, 'water_label_SAMPLED'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load eopatch\n",
    "load_task = LoadTask(f'{EOP_DIR}/eopatches/')\n",
    "\n",
    "# Keep only B02, B03, B04\n",
    "extract_task = ExtractBandsTask(input_feature=BANDS_FEATURE, \n",
    "                                output_feature=BANDS_SUB_FEATURE, \n",
    "                                bands=[S2_BANDS.index(s2b) for s2b in ['B02', 'B03', 'B04']])\n",
    "\n",
    "# NDWI = (B03 - B08) / (B03 + B08)\n",
    "ndwi_task = NormalizedDifferenceIndexTask(input_feature=BANDS_FEATURE,\n",
    "                                          output_feature=NDWI_FEATURE,\n",
    "                                          bands=[S2_BANDS.index(s2b) for s2b in ['B03', 'B08']])\n",
    "\n",
    "# NDMI = (B08 - B11) / (B08 + B11)\n",
    "ndmi_task = NormalizedDifferenceIndexTask(input_feature=BANDS_FEATURE,\n",
    "                                          output_feature=NDMI_FEATURE,\n",
    "                                          bands=[S2_BANDS.index(s2b) for s2b in ['B08', 'B11']])\n",
    "\n",
    "# Merge features as [B02, B03, B04, NDWI, NDMI]\n",
    "merge_task = MergeFeatureTask(input_features=[BANDS_SUB_FEATURE, NDWI_FEATURE, NDMI_FEATURE],\n",
    "                              output_feature=FEATURES)\n",
    "\n",
    "# Task for pixels' sampling\n",
    "sampling_task = PointSamplingTask(\n",
    "    n_samples=N_SAMPLES, \n",
    "    ref_mask_feature=LABELS[1], \n",
    "    ref_labels=REF_LABELS, \n",
    "    sample_features=[  # tag fields to sample\n",
    "        FEATURES,\n",
    "        IS_DATA_FEATURE,\n",
    "        LABELS\n",
    "    ])\n",
    "\n",
    "# Add to exising EOPatch only the sampled features and labels\n",
    "save_task = SaveTask(\n",
    "    f'{EOP_DIR}/eopatches/', \n",
    "    features=[FEATURES_SAMPLED, IS_DATA_SAMPLED, LABELS_SAMPLED],\n",
    "    overwrite_permission=OverwritePermission.OVERWRITE_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the workflow\n",
    "workflow = LinearWorkflow(\n",
    "    load_task,\n",
    "    extract_task,\n",
    "    ndwi_task,\n",
    "    ndmi_task,\n",
    "    merge_task,\n",
    "    sampling_task,\n",
    "    save_task\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e05b4ec3760249489d7efebbaf409f7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7671), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1min 48s, sys: 2.78 s, total: 1min 51s\n",
      "Wall time: 3min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Create list of arguments to be passed at run-time\n",
    "execution_args = []\n",
    "for idx, eop_name in enumerate(eopatch_names):\n",
    "    execution_args.append({\n",
    "        load_task: {'eopatch_folder': eop_name},\n",
    "        sampling_task: {'seed': idx},\n",
    "        save_task: {'eopatch_folder': eop_name}\n",
    "    })\n",
    "    \n",
    "# Execute workflow in parallel, e.g. each EOPatch is process in parallel in dedicated processes\n",
    "executor = EOExecutor(workflow, execution_args, save_logs=True)\n",
    "executor.run(workers=N_WORKERS, multiprocess=True)\n",
    "\n",
    "# Make report to check possible failures\n",
    "executor.make_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EOPatch(\n",
       "  data: {\n",
       "    BANDS-S2-L1C: numpy.ndarray(shape=(1, 64, 64, 13), dtype=float32)\n",
       "    FEATURES_SAMPLED: numpy.ndarray(shape=(1, 100, 1, 5), dtype=float32)\n",
       "    TRUE-COLOR-S1-IW-DES: numpy.ndarray(shape=(1, 64, 64, 3), dtype=float32)\n",
       "  }\n",
       "  mask: {\n",
       "    IS_DATA: numpy.ndarray(shape=(1, 64, 64, 1), dtype=bool)\n",
       "    IS_DATA_S1_IW_DES: numpy.ndarray(shape=(1, 64, 64, 1), dtype=bool)\n",
       "    IS_DATA_SAMPLED: numpy.ndarray(shape=(1, 100, 1, 1), dtype=bool)\n",
       "  }\n",
       "  scalar: {}\n",
       "  label: {}\n",
       "  vector: {}\n",
       "  data_timeless: {\n",
       "    DEM: numpy.ndarray(shape=(64, 64, 1), dtype=float32)\n",
       "  }\n",
       "  mask_timeless: {\n",
       "    water_label: numpy.ndarray(shape=(64, 64, 1), dtype=uint8)\n",
       "    water_label_SAMPLED: numpy.ndarray(shape=(100, 1, 1), dtype=uint8)\n",
       "  }\n",
       "  scalar_timeless: {}\n",
       "  label_timeless: {}\n",
       "  vector_timeless: {}\n",
       "  meta_info: {\n",
       "    TRUE-COLOR-S1-IW-DES: datetime.timedelta(-2, 6658)\n",
       "    maxcc: 1.0\n",
       "    service_type: 'wms'\n",
       "    size_x: 64\n",
       "    size_y: 64\n",
       "    time_difference: datetime.timedelta(1)\n",
       "    time_interval: (datetime.datetime(2017, 8, 12, 0, 0), datetime.datetime(2017, 8, 13, 0, 0))\n",
       "    timestamp: '2017-08-12'\n",
       "  }\n",
       "  bbox: BBox(((64.47018117599022, 50.951253746594006), (64.47931440474328, 50.9570068827248)), crs=CRS('4326'))\n",
       "  timestamp: [datetime.datetime(2017, 8, 12, 6, 47, 48)]\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eop = EOPatch.load(f'{EOP_DIR}/eopatches/{eopatch_names[1]}')\n",
    "eop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train/cval/test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split eopatches into train/test sets based on location and timestamps, e.g. images from same and different timestamps will end up in same set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf['x']=gdf.geometry.apply(lambda g: g.centroid.x)\n",
    "gdf['y']=gdf.geometry.apply(lambda g: g.centroid.y)\n",
    "db = DBSCAN(eps=0.1, min_samples=1, algorithm='ball_tree', metric='euclidean').fit(gdf[['x', 'y']].to_numpy())\n",
    "for label in set(db.labels_):\n",
    "    class_member_mask = (db.labels_ == label)\n",
    "    gdf.loc[class_member_mask,'cluster_id'] = label\n",
    "    \n",
    "gdf['group'] = gdf.groupby(by=['cluster_id','timestamp'],as_index=False).ngroup()\n",
    "gdf.drop(columns=['x','y','cluster_id'], inplace=True)\n",
    "\n",
    "train_ids = set(np.where(np.random.rand(gdf.group.nunique())<=TRAIN_RATIO)[0])\n",
    "\n",
    "gdf['isin_train'] = gdf.group.isin(train_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_DEM</th>\n",
       "      <th>has_S1_ASC</th>\n",
       "      <th>has_S1_DES</th>\n",
       "      <th>has_S2</th>\n",
       "      <th>task_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>window_height</th>\n",
       "      <th>window_width</th>\n",
       "      <th>geometry</th>\n",
       "      <th>group</th>\n",
       "      <th>isin_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6b73fd74a2eb11e994fbf0db728b8d14</td>\n",
       "      <td>2016-09-26</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>POLYGON ((65.84065 52.68916, 65.84065 52.69491...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0a27f4aea2eb11e9bfdaa9140581204c</td>\n",
       "      <td>2017-08-12</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>POLYGON ((64.47018 50.95125, 64.47018 50.95701...</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9b60193ea24111e98d7d929084d604de</td>\n",
       "      <td>2019-03-23</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>POLYGON ((31.15408 38.61106, 31.15408 38.61600...</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9afaabaea24111e983d185262381d01a</td>\n",
       "      <td>2018-05-31</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>POLYGON ((-1.60285 38.21084, -1.60285 38.21558...</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9dfb5254a24111e9a087737fe71fcff1</td>\n",
       "      <td>2018-05-27</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>POLYGON ((48.22342 48.99523, 48.22342 49.00099...</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   has_DEM  has_S1_ASC  has_S1_DES  has_S2                           task_id  \\\n",
       "0        1           0           0       1  6b73fd74a2eb11e994fbf0db728b8d14   \n",
       "1        1           0           1       1  0a27f4aea2eb11e9bfdaa9140581204c   \n",
       "2        1           1           1       1  9b60193ea24111e98d7d929084d604de   \n",
       "3        1           1           1       1  9afaabaea24111e983d185262381d01a   \n",
       "4        1           0           1       1  9dfb5254a24111e9a087737fe71fcff1   \n",
       "\n",
       "    timestamp  window_height  window_width  \\\n",
       "0  2016-09-26             64            64   \n",
       "1  2017-08-12             64            64   \n",
       "2  2019-03-23             64            64   \n",
       "3  2018-05-31             64            64   \n",
       "4  2018-05-27             64            64   \n",
       "\n",
       "                                            geometry  group  isin_train  \n",
       "0  POLYGON ((65.84065 52.68916, 65.84065 52.69491...      1       False  \n",
       "1  POLYGON ((64.47018 50.95125, 64.47018 50.95701...      3        True  \n",
       "2  POLYGON ((31.15408 38.61106, 31.15408 38.61600...      4        True  \n",
       "3  POLYGON ((-1.60285 38.21084, -1.60285 38.21558...      5        True  \n",
       "4  POLYGON ((48.22342 48.99523, 48.22342 49.00099...      7       False  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e906500e387e433bacce2d404168617e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7671), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# load sampled eopatches\n",
    "eopatches = []\n",
    "\n",
    "for eopatch_name in tqdm(eopatch_names):\n",
    "    eopatches.append(EOPatch.load(f'{EOP_DIR}/eopatches/{eopatch_name}', lazy_loading=True))    \n",
    "\n",
    "eopatches = np.array(eopatches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the features and the labels for train and test sets\n",
    "features_train = np.array([eopatch[FEATURES_SAMPLED] for eopatch in eopatches[gdf.isin_train.values]])\n",
    "labels_train = np.array([eopatch[LABELS_SAMPLED] for eopatch in eopatches[gdf.isin_train.values]])\n",
    "mask_train = np.array([eopatch[IS_DATA_SAMPLED] for eopatch in eopatches[gdf.isin_train.values]])\n",
    "\n",
    "features_test = np.array([eopatch[FEATURES_SAMPLED] for eopatch in eopatches[~gdf.isin_train.values]])\n",
    "labels_test = np.array([eopatch[LABELS_SAMPLED] for eopatch in eopatches[~gdf.isin_train.values]])\n",
    "mask_test = np.array([eopatch[IS_DATA_SAMPLED] for eopatch in eopatches[~gdf.isin_train.values]])\n",
    "\n",
    "# get shape\n",
    "p1, t, w, h, f = features_train.shape\n",
    "p2, t, w, h, f = features_test.shape\n",
    "p = p1 + p2\n",
    "\n",
    "# reshape to n x m\n",
    "features_train = np.moveaxis(features_train, 1, 3).reshape(p1 * w * h, t * f)\n",
    "labels_train = np.moveaxis(labels_train, 1, 2).reshape(p1 * w * h, 1).squeeze()\n",
    "mask_train = np.moveaxis(mask_train, 1, 2).reshape(p1 * w * h, 1).squeeze()\n",
    "\n",
    "features_test = np.moveaxis(features_test, 1, 3).reshape(p2 * w * h, t * f)\n",
    "labels_test = np.moveaxis(labels_test, 1, 2).reshape(p2 * w * h, 1).squeeze()\n",
    "mask_test = np.moveaxis(mask_test, 1, 2).reshape(p2 * w * h, 1).squeeze()\n",
    "\n",
    "# remove points with no valid data\n",
    "features_train = features_train[mask_train]\n",
    "labels_train = labels_train[mask_train]\n",
    "\n",
    "features_test = features_test[mask_test]\n",
    "labels_test = labels_test[mask_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((610300, 5), (610300,), (156800, 5), (156800,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train.shape, labels_train.shape, features_test.shape, labels_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([0, 1], dtype=uint8), array([218908, 391392])),\n",
       " (array([0, 1], dtype=uint8), array([ 53657, 103143])))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(labels_train, return_counts=True), np.unique(labels_test, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and evaluate model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.95 s, sys: 23.6 ms, total: 1.97 s\n",
      "Wall time: 306 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Set up the model\n",
    "model = lgbm.LGBMClassifier(\n",
    "    objective='binary', \n",
    "    n_estimators=10,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# train the model\n",
    "model.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the test labels\n",
    "plabels_test = model.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy 92.2%\n",
      "Classification F1-score 92.2%\n",
      "\n",
      "             Class              =  F1  | Recall | Precision\n",
      "         --------------------------------------------------\n",
      "         * non-water            = 88.4 |  86.8  | 90.0\n",
      "         * water                = 94.1 |  95.0  | 93.3\n"
     ]
    }
   ],
   "source": [
    "class_labels = REF_LABELS\n",
    "class_names = ['non-water', 'water']\n",
    "mask = np.in1d(plabels_test, labels_test)\n",
    "pred = plabels_test[mask]\n",
    "lbls = labels_test[mask]\n",
    "\n",
    "f1_scores = metrics.f1_score(lbls, pred, labels=class_labels, average=None)\n",
    "recall = metrics.recall_score(lbls, pred, labels=class_labels, average=None)\n",
    "precision = metrics.precision_score(lbls, pred, labels=class_labels, average=None) \n",
    "\n",
    "print('Classification accuracy {:.1f}%'.format(100 * metrics.accuracy_score(lbls, pred)))\n",
    "print('Classification F1-score {:.1f}%'.format(100 * metrics.f1_score(lbls, pred, average='weighted')))\n",
    "print()\n",
    "print('             Class              =  F1  | Recall | Precision')\n",
    "print('         --------------------------------------------------')\n",
    "for idx, classname in enumerate([class_names[idx] for idx in class_labels]):\n",
    "    print('         * {0:20s} = {1:2.1f} |  {2:2.1f}  | {3:2.1f}'.format(classname, \n",
    "                                                                         f1_scores[idx] * 100, \n",
    "                                                                         recall[idx] * 100, \n",
    "                                                                         precision[idx] * 100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([54, 63, 13, 79, 91])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert model to evalscript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test evalscript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
