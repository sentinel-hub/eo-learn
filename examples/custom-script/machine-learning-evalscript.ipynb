{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and run a Machine Learning model as a custom-script\n",
    "\n",
    "This notebook showcases how to create a Machine Learning (ML) custom-script for water detection. The workflow uses [eo-learn](https://eo-learn.readthedocs.io/en/latest/) to process the data and [LightGBM](https://lightgbm.readthedocs.io/en/latest/) to train a ML model for water classification given Seninel-2 band and index values. The resulting custom-script can be used in [the Sentinel Hub EOBrowser](https://www-test.sentinel-hub.com/explore/eobrowser/), in the [multi-temporal instance of Sentinel Playground](https://apps.sentinel-hub.com/sentinel-playground-temporal/?source=S2&lat=40.4&lng=-3.730000000000018&zoom=12&preset=1-NATURAL-COLOR&layers=B04,B03,B02&maxcc=20&gain=1.0&temporal=true&gamma=1.0&time=2015-01-01%7C2019-10-02&atmFilter=&showDates=false) and as evalscript in the [Sentinel Hub process API](https://docs.sentinel-hub.com/api/latest/api/process/).\n",
    "\n",
    "The workflow is as follows:\n",
    "\n",
    " * download training and testing data\n",
    " * prepare samples for ML algorithm\n",
    " * train ML model\n",
    " * export trained model as custom-script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/devis/anaconda3/envs/eo-learn-develop/lib/python3.6/site-packages/_pytest/mark/structures.py:350: DeprecationWarning: The usage of `cmp` is deprecated and will be removed on or after 2021-06-01.  Please use `eq` and `order` instead.\n",
      "  @attr.s(cmp=False, hash=False)\n"
     ]
    }
   ],
   "source": [
    "# Jupyter notebook related\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "# Built-in modules\n",
    "import urllib.request\n",
    "import shutil\n",
    "import zipfile\n",
    "\n",
    "# # Basics of Python data handling and visualization\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "# import matplotlib as mpl\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.gridspec as gridspec\n",
    "# from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "# from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "# from shapely.geometry import Polygon\n",
    "# from tqdm.auto import tqdm\n",
    "\n",
    "# # Machine learning \n",
    "# import lightgbm as lgb\n",
    "# import joblib\n",
    "# from sklearn import metrics\n",
    "# from sklearn import preprocessing\n",
    "\n",
    "# # Imports from eo-learn and sentinelhub-py\n",
    "from eolearn.core import EOPatch, EOTask, LinearWorkflow, FeatureType, OverwritePermission, \\\n",
    "    LoadTask, SaveTask, EOExecutor, ExtractBandsTask, MergeFeatureTask\n",
    "from eolearn.features import NormalizedDifferenceIndexTask\n",
    "from eolearn.geometry import PointSamplingTask #, ErosionTask, VectorToRaster\n",
    "# from eolearn.io import SentinelHubInputTask, ExportToTiff\n",
    "# from eolearn.mask import AddMultiCloudMaskTask, AddValidDataMaskTask\n",
    "# from sentinelhub import UtmZoneSplitter, BBox, CRS, DataSource"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the data\n",
    "\n",
    "* used to improve the blue-bot observatory\n",
    "* collected with the Classification App\n",
    "* available on bucket\n",
    "* info on what they contain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up url and data paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_URL = 'http://queryplanet.sentinel-hub.com/water-labels'\n",
    "\n",
    "DATA_INFO = f'{DATA_URL}/data-info.geojson'\n",
    "EOP_URL = f'{DATA_URL}/eopatches.zip'\n",
    "\n",
    "EOP_ZIP = './eopatches.zip'\n",
    "EOP_DIR = '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "S2_BANDS = ['B01', 'B02', 'B03', 'B04', 'B05', 'B06', 'B07', 'B08', 'B8A', 'B09', 'B10', 'B11', 'B12']\n",
    "S2_BANDS_STR = ','.join(S2_BANDS)\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "TRAIN_RATIO = .8\n",
    "\n",
    "N_WORKERS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file(DATA_INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_DEM</th>\n",
       "      <th>has_S1_ASC</th>\n",
       "      <th>has_S1_DES</th>\n",
       "      <th>has_S2</th>\n",
       "      <th>task_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>window_height</th>\n",
       "      <th>window_width</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6b73fd74a2eb11e994fbf0db728b8d14</td>\n",
       "      <td>2016-09-26</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>POLYGON ((65.84065 52.68916, 65.84065 52.69491...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0a27f4aea2eb11e9bfdaa9140581204c</td>\n",
       "      <td>2017-08-12</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>POLYGON ((64.47018 50.95125, 64.47018 50.95701...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9b60193ea24111e98d7d929084d604de</td>\n",
       "      <td>2019-03-23</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>POLYGON ((31.15408 38.61106, 31.15408 38.61600...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9afaabaea24111e983d185262381d01a</td>\n",
       "      <td>2018-05-31</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>POLYGON ((-1.60285 38.21084, -1.60285 38.21558...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9dfb5254a24111e9a087737fe71fcff1</td>\n",
       "      <td>2018-05-27</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>POLYGON ((48.22342 48.99523, 48.22342 49.00099...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   has_DEM  has_S1_ASC  has_S1_DES  has_S2                           task_id  \\\n",
       "0        1           0           0       1  6b73fd74a2eb11e994fbf0db728b8d14   \n",
       "1        1           0           1       1  0a27f4aea2eb11e9bfdaa9140581204c   \n",
       "2        1           1           1       1  9b60193ea24111e98d7d929084d604de   \n",
       "3        1           1           1       1  9afaabaea24111e983d185262381d01a   \n",
       "4        1           0           1       1  9dfb5254a24111e9a087737fe71fcff1   \n",
       "\n",
       "    timestamp  window_height  window_width  \\\n",
       "0  2016-09-26             64            64   \n",
       "1  2017-08-12             64            64   \n",
       "2  2019-03-23             64            64   \n",
       "3  2018-05-31             64            64   \n",
       "4  2018-05-27             64            64   \n",
       "\n",
       "                                            geometry  \n",
       "0  POLYGON ((65.84065 52.68916, 65.84065 52.69491...  \n",
       "1  POLYGON ((64.47018 50.95125, 64.47018 50.95701...  \n",
       "2  POLYGON ((31.15408 38.61106, 31.15408 38.61600...  \n",
       "3  POLYGON ((-1.60285 38.21084, -1.60285 38.21558...  \n",
       "4  POLYGON ((48.22342 48.99523, 48.22342 49.00099...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7671, 7671)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gdf), len(gdf[gdf.has_S2==1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and unzip file with eopatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://queryplanet.sentinel-hub.com/water-labels/eopatches.zip to ./eopatches.zip..\n",
      "Unzipping ./eopatches.zip to ...\n"
     ]
    }
   ],
   "source": [
    "print(f'Downloading {EOP_URL} to {EOP_ZIP} ..')\n",
    "with urllib.request.urlopen(EOP_URL) as response, open(EOP_ZIP, 'wb') as zip_file:\n",
    "    shutil.copyfileobj(response, zip_file)\n",
    "    \n",
    "print(f'Unzipping {EOP_ZIP} to {EOP_DIR} ..')\n",
    "with zipfile.ZipFile(EOP_ZIP, 'r') as zip_file:\n",
    "    zip_file.extractall(EOP_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7672\r\n"
     ]
    }
   ],
   "source": [
    "ls -lth {EOP_DIR}/eopatches | wc -l "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up and run feature processing workflow with `eo-learn`\n",
    "\n",
    "* load eopatches\n",
    "* keep only B02, B03 and B04\n",
    "* add NDWI and NDMI\n",
    "* sample pixels\n",
    "* save sampled arrays only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build name of eopatches, given by index of `data_info`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "eopatch_names = [f'eopatch-{idx:04d}' for idx in np.arange(len(gdf))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load an eopathc and inspect content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EOPatch(\n",
       "  data: {\n",
       "    BANDS-S2-L1C: numpy.ndarray(shape=(1, 64, 64, 13), dtype=float32)\n",
       "    TRUE-COLOR-S1-IW-DES: numpy.ndarray(shape=(1, 64, 64, 3), dtype=float32)\n",
       "  }\n",
       "  mask: {\n",
       "    IS_DATA: numpy.ndarray(shape=(1, 64, 64, 1), dtype=bool)\n",
       "    IS_DATA_S1_IW_DES: numpy.ndarray(shape=(1, 64, 64, 1), dtype=bool)\n",
       "  }\n",
       "  scalar: {}\n",
       "  label: {}\n",
       "  vector: {}\n",
       "  data_timeless: {\n",
       "    DEM: numpy.ndarray(shape=(64, 64, 1), dtype=float32)\n",
       "  }\n",
       "  mask_timeless: {\n",
       "    water_label: numpy.ndarray(shape=(64, 64, 1), dtype=uint8)\n",
       "  }\n",
       "  scalar_timeless: {}\n",
       "  label_timeless: {}\n",
       "  vector_timeless: {}\n",
       "  meta_info: {\n",
       "    TRUE-COLOR-S1-IW-DES: datetime.timedelta(-2, 6658)\n",
       "    maxcc: 1.0\n",
       "    service_type: 'wms'\n",
       "    size_x: 64\n",
       "    size_y: 64\n",
       "    time_difference: datetime.timedelta(1)\n",
       "    time_interval: (datetime.datetime(2017, 8, 12, 0, 0), datetime.datetime(2017, 8, 13, 0, 0))\n",
       "    timestamp: '2017-08-12'\n",
       "  }\n",
       "  bbox: BBox(((64.47018117599022, 50.951253746594006), (64.47931440474328, 50.9570068827248)), crs=CRS('4326'))\n",
       "  timestamp: [datetime.datetime(2017, 8, 12, 6, 47, 48)]\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eop = EOPatch.load(f'{EOP_DIR}/eopatches/{eopatch_names[1]}')\n",
    "eop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "BANDS_FEATURE = FeatureType.DATA, 'BANDS-S2-L1C'\n",
    "IS_DATA_FEATURE = FeatureType.MASK, 'IS_DATA'\n",
    "\n",
    "BANDS_SUB_FEATURE = FeatureType.DATA, 'BANDS-SUBSET'\n",
    "NDWI_FEATURE = FeatureType.DATA, 'NDWI'\n",
    "NDMI_FEATURE = FeatureType.DATA, 'NDMI'\n",
    "\n",
    "FEATURES = FeatureType.DATA, 'FEATURES'\n",
    "\n",
    "LABELS = FeatureType.MASK_TIMELESS, 'water_label'\n",
    "\n",
    "FEATURES_SAMPLED = FeatureType.DATA, 'FEATURES_SAMPLED'\n",
    "IS_DATA_SAMPLED = FeatureType.MASK, 'IS_DATA_SAMPLED'\n",
    "LABELS_SAMPLED = FeatureType.MASK_TIMELESS, 'water_label_SAMPLED'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load eopatch\n",
    "load_task = LoadTask(f'{EOP_DIR}/eopatches/')\n",
    "\n",
    "# Keep only B02, B03, B04\n",
    "extract_task = ExtractBandsTask(input_feature=BANDS_FEATURE, \n",
    "                                output_feature=BANDS_SUB_FEATURE, \n",
    "                                bands=[S2_BANDS.index(s2b) for s2b in ['B02', 'B03', 'B04']])\n",
    "\n",
    "# NDWI = (B03 - B08) / (B03 + B08)\n",
    "ndwi_task = NormalizedDifferenceIndexTask(input_feature=BANDS_FEATURE,\n",
    "                                          output_feature=NDWI_FEATURE,\n",
    "                                          bands=[S2_BANDS.index(s2b) for s2b in ['B03', 'B08']])\n",
    "\n",
    "# NDMI = (B08 - B11) / (B08 + B11)\n",
    "ndmi_task = NormalizedDifferenceIndexTask(input_feature=BANDS_FEATURE,\n",
    "                                          output_feature=NDMI_FEATURE,\n",
    "                                          bands=[S2_BANDS.index(s2b) for s2b in ['B08', 'B11']])\n",
    "\n",
    "# Merge features as [B02, B03, B04, NDWI, NDMI]\n",
    "merge_task = MergeFeatureTask(input_features=[BANDS_SUB_FEATURE, NDWI_FEATURE, NDMI_FEATURE],\n",
    "                              output_feature=FEATURES)\n",
    "\n",
    "# Task for pixels' sampling\n",
    "N_SAMPLES = 1000\n",
    "REF_LABELS = [0, 1]  \n",
    "sampling_task = PointSamplingTask(\n",
    "    n_samples=N_SAMPLES, \n",
    "    ref_mask_feature=LABELS[1], \n",
    "    ref_labels=REF_LABELS, \n",
    "    sample_features=[  # tag fields to sample\n",
    "        FEATURES,\n",
    "        IS_DATA_FEATURE,\n",
    "        LABELS\n",
    "    ])\n",
    "\n",
    "# Add to exising EOPatch only the sampled features and labels\n",
    "save_task = SaveTask(\n",
    "    f'{EOP_DIR}/eopatches/', \n",
    "    features=[FEATURES_SAMPLED, IS_DATA_SAMPLED, LABELS_SAMPLED],\n",
    "    overwrite_permission=OverwritePermission.OVERWRITE_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the workflow\n",
    "workflow = LinearWorkflow(\n",
    "    load_task,\n",
    "    extract_task,\n",
    "    ndwi_task,\n",
    "    ndmi_task,\n",
    "    merge_task,\n",
    "    sampling_task,\n",
    "    save_task\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7204d2282ba4ea0832bc26fb7d45c31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7671), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1min 44s, sys: 2.79 s, total: 1min 47s\n",
      "Wall time: 3min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Create list of arguments to be passed at run-time\n",
    "execution_args = []\n",
    "for idx, eop_name in enumerate(eopatch_names):\n",
    "    execution_args.append({\n",
    "        load_task: {'eopatch_folder': eop_name},\n",
    "        sampling_task: {'seed': idx},\n",
    "        save_task: {'eopatch_folder': eop_name}\n",
    "    })\n",
    "    \n",
    "# Execute workflow in parallel, e.g. each EOPatch is process in parallel in dedicated processes\n",
    "executor = EOExecutor(workflow, execution_args, save_logs=True)\n",
    "executor.run(workers=N_WORKERS, multiprocess=True)\n",
    "\n",
    "# Make report to check possible failures\n",
    "executor.make_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EOPatch(\n",
       "  data: {\n",
       "    BANDS-S2-L1C: numpy.ndarray(shape=(1, 64, 64, 13), dtype=float32)\n",
       "    FEATURES_SAMPLED: numpy.ndarray(shape=(1, 1000, 1, 5), dtype=float32)\n",
       "    TRUE-COLOR-S1-IW-DES: numpy.ndarray(shape=(1, 64, 64, 3), dtype=float32)\n",
       "  }\n",
       "  mask: {\n",
       "    IS_DATA: numpy.ndarray(shape=(1, 64, 64, 1), dtype=bool)\n",
       "    IS_DATA_S1_IW_DES: numpy.ndarray(shape=(1, 64, 64, 1), dtype=bool)\n",
       "    IS_DATA_SAMPLED: numpy.ndarray(shape=(1, 1000, 1, 1), dtype=bool)\n",
       "  }\n",
       "  scalar: {}\n",
       "  label: {}\n",
       "  vector: {}\n",
       "  data_timeless: {\n",
       "    DEM: numpy.ndarray(shape=(64, 64, 1), dtype=float32)\n",
       "  }\n",
       "  mask_timeless: {\n",
       "    water_label: numpy.ndarray(shape=(64, 64, 1), dtype=uint8)\n",
       "    water_label_SAMPLED: numpy.ndarray(shape=(1000, 1, 1), dtype=uint8)\n",
       "  }\n",
       "  scalar_timeless: {}\n",
       "  label_timeless: {}\n",
       "  vector_timeless: {}\n",
       "  meta_info: {\n",
       "    TRUE-COLOR-S1-IW-DES: datetime.timedelta(-2, 6658)\n",
       "    maxcc: 1.0\n",
       "    service_type: 'wms'\n",
       "    size_x: 64\n",
       "    size_y: 64\n",
       "    time_difference: datetime.timedelta(1)\n",
       "    time_interval: (datetime.datetime(2017, 8, 12, 0, 0), datetime.datetime(2017, 8, 13, 0, 0))\n",
       "    timestamp: '2017-08-12'\n",
       "  }\n",
       "  bbox: BBox(((64.47018117599022, 50.951253746594006), (64.47931440474328, 50.9570068827248)), crs=CRS('4326'))\n",
       "  timestamp: [datetime.datetime(2017, 8, 12, 6, 47, 48)]\n",
       ")"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eop = EOPatch.load(f'{EOP_DIR}/eopatches/{eopatch_names[1]}')\n",
    "eop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train/cval/test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split eopatches into train/test sets based on location and timestamps, e.g. images from same and different timestamps will end up in same set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_sets = []\n",
    "# loop over unique time-stamps\n",
    "for timestamp in gdf['timestamp'].unique():\n",
    "    # get geometries with same time-stamp\n",
    "    centroids = gdf[gdf['timestamp']==timestamp].geometry.centroid\n",
    "    indices = centroids.keys()\n",
    "    \n",
    "    # compute centroids\n",
    "    centroids = np.array([np.array(centroid) for centroid in centroids])\n",
    "    ctr_mean = np.mean(centroids, axis=0)\n",
    "    ctr_std = np.std(centroids, axis=0)\n",
    "    \n",
    "    # if centroids are close together, put them in same set\n",
    "    if all(pt < 2 for pt in ctr_std):\n",
    "        index_sets.append(indices)\n",
    "        continue\n",
    "        \n",
    "    else:\n",
    "    \n",
    "        # sort geometries and put geometries together if centroids are within 2degree\n",
    "        sorted_indices = np.argsort(centroids, axis=0)\n",
    "        coord_diff = np.diff(centroids[sorted_indices[:, 0]], axis=0)\n",
    "        diff_norm = np.linalg.norm(coord_diff, axis=-1)\n",
    "        index_breaks, = np.where(diff_norm > 2)\n",
    "        for nib, ib in enumerate(index_breaks):\n",
    "            ileft = int(0) if nib == 0 else int(index_breaks[nib-1])\n",
    "            iright = int(ib+1)\n",
    "            index_sets.append(indices[sorted_indices[:, 0]][ileft:iright])\n",
    "        index_sets.append(indices[sorted_indices[:, 0]][iright:])\n",
    "        del iright, ileft\n",
    "\n",
    "train_ids = set(np.where(np.random.rand(len(index_sets))<=TRAIN_RATIO)[0])\n",
    "test_ids = set(np.arange(len(index_sets))) - train_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eop_ids = np.unique((np.hstack([np.uint64(index_sets[itrain]) for itrain in train_ids])))\n",
    "test_eop_ids = np.unique(np.hstack([np.uint64(index_sets[itest]) for itest in test_ids]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and evaluate model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert model to evalscript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test evalscript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
