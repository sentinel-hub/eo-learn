{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and run a Machine Learning model as a custom-script\n",
    "\n",
    "This notebook showcases how to create a Machine Learning (ML) custom-script for water detection. \n",
    "\n",
    "The workflow uses [eo-learn](https://eo-learn.readthedocs.io/en/latest/) to process the data and [LightGBM](https://lightgbm.readthedocs.io/en/latest/) to train a ML model for water classification given Seninel-2 band and index values. The resulting custom-script can be used in [the Sentinel Hub EOBrowser](https://www-test.sentinel-hub.com/explore/eobrowser/), in the [multi-temporal instance of Sentinel Playground](https://apps.sentinel-hub.com/sentinel-playground-temporal/?source=S2&lat=40.4&lng=-3.730000000000018&zoom=12&preset=1-NATURAL-COLOR&layers=B04,B03,B02&maxcc=20&gain=1.0&temporal=true&gamma=1.0&time=2015-01-01%7C2019-10-02&atmFilter=&showDates=false) and as evalscript in the [Sentinel Hub process API](https://docs.sentinel-hub.com/api/latest/api/process/).\n",
    "\n",
    "The workflow is organised as follows:\n",
    "\n",
    " * [Data download](#Data-download)\n",
    " * [Features preparation](#Features-preparationn)\n",
    " * [Create train and test sets](#Create-train-and-test-sets)\n",
    " * [Train and evaluate model](#Train-and-evaluate-model)\n",
    " * [Convert model to evalscript](#Convert-model-to-evalscript)\n",
    " * [Test evalscript](#Test-evalscript)\n",
    " * [Possible improvements](#Possible-improvements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jupyter notebook related\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "# Built-in modules\n",
    "import urllib.request\n",
    "import shutil\n",
    "import zipfile\n",
    "\n",
    "# Basics of Python data handling and visualization\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Machine learning \n",
    "from sklearn.cluster import DBSCAN\n",
    "import lightgbm as lgbm\n",
    "from lightgbm import Booster\n",
    "import joblib\n",
    "from sklearn import metrics\n",
    "\n",
    "# Imports from eo-learn and sentinelhub-py\n",
    "from eolearn.core import EOPatch, EOTask, LinearWorkflow, FeatureType, OverwritePermission, \\\n",
    "    LoadTask, SaveTask, EOExecutor, ExtractBandsTask, MergeFeatureTask\n",
    "from eolearn.features import NormalizedDifferenceIndexTask\n",
    "from eolearn.geometry import PointSamplingTask \n",
    "# from eolearn.io import SentinelHubInputTask\n",
    "# from sentinelhub import UtmZoneSplitter, BBox, CRS, DataSource\n",
    "\n",
    "# Local imports for utility functions\n",
    "from lgbm_to_evalscript_utils import parse_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "S2_BANDS = ['B01', 'B02', 'B03', 'B04', 'B05', 'B06', 'B07', 'B08', 'B8A', 'B09', 'B10', 'B11', 'B12']\n",
    "S2_BANDS_STR = ','.join(S2_BANDS)\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "TRAIN_RATIO = .8\n",
    "\n",
    "N_WORKERS = 4\n",
    "\n",
    "N_SAMPLES = 100\n",
    "REF_LABELS = [0, 1]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data download\n",
    "\n",
    "The dataset used in this notebook is openly available on [queryplanet.sentinel-hub.com](http://queryplanet.sentinel-hub.com/index.html), and has been crowd-sourced through a labelling campaign on [ClassificationApp](https://apps.sentinel-hub.com/classificationApp/#/campaigns/2d89a0ae774111e98ffbb97eadc8b396).\n",
    "\n",
    "The aim of the campaign is to collect labels for water detection using Sentinel-2 bands. The water detection algorithm can be used to improve the current algorithm employed in the [BlueDot Observatory](https://water.blue-dot-observatory.com).\n",
    "\n",
    "The dataset contains **7671** `EOPatch`es. Each `EOPatch` contains all 13 Sentinel-2 L1C of size `64x64` pixels, as well as the Mapzen Digital Elevation Model. In addition, where applicable, `EOPatch`es contain a Sentinel-1 acquisition having the closest date to the Sentinel-2 acquisition. The Sentinel-2 timestamp and bounding box are as well stored in the `meta_info` of the `EOPatch`.\n",
    "\n",
    "An overview of the dataset content is available in the `data-info.geojson` file, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_URL = 'http://queryplanet.sentinel-hub.com/water-labels'\n",
    "\n",
    "DATA_INFO = f'{DATA_URL}/data-info.geojson'\n",
    "EOP_URL = f'{DATA_URL}/eopatches.zip'\n",
    "\n",
    "# Modify these paths to your local environment\n",
    "EOP_ZIP = './eopatches.zip'\n",
    "EOP_DIR = '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file(DATA_INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_DEM</th>\n",
       "      <th>has_S1_ASC</th>\n",
       "      <th>has_S1_DES</th>\n",
       "      <th>has_S2</th>\n",
       "      <th>task_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>window_height</th>\n",
       "      <th>window_width</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6b73fd74a2eb11e994fbf0db728b8d14</td>\n",
       "      <td>2016-09-26</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>POLYGON ((65.84065 52.68916, 65.84065 52.69491...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0a27f4aea2eb11e9bfdaa9140581204c</td>\n",
       "      <td>2017-08-12</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>POLYGON ((64.47018 50.95125, 64.47018 50.95701...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9b60193ea24111e98d7d929084d604de</td>\n",
       "      <td>2019-03-23</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>POLYGON ((31.15408 38.61106, 31.15408 38.61600...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9afaabaea24111e983d185262381d01a</td>\n",
       "      <td>2018-05-31</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>POLYGON ((-1.60285 38.21084, -1.60285 38.21558...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9dfb5254a24111e9a087737fe71fcff1</td>\n",
       "      <td>2018-05-27</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>POLYGON ((48.22342 48.99523, 48.22342 49.00099...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   has_DEM  has_S1_ASC  has_S1_DES  has_S2                           task_id  \\\n",
       "0        1           0           0       1  6b73fd74a2eb11e994fbf0db728b8d14   \n",
       "1        1           0           1       1  0a27f4aea2eb11e9bfdaa9140581204c   \n",
       "2        1           1           1       1  9b60193ea24111e98d7d929084d604de   \n",
       "3        1           1           1       1  9afaabaea24111e983d185262381d01a   \n",
       "4        1           0           1       1  9dfb5254a24111e9a087737fe71fcff1   \n",
       "\n",
       "    timestamp  window_height  window_width  \\\n",
       "0  2016-09-26             64            64   \n",
       "1  2017-08-12             64            64   \n",
       "2  2019-03-23             64            64   \n",
       "3  2018-05-31             64            64   \n",
       "4  2018-05-27             64            64   \n",
       "\n",
       "                                            geometry  \n",
       "0  POLYGON ((65.84065 52.68916, 65.84065 52.69491...  \n",
       "1  POLYGON ((64.47018 50.95125, 64.47018 50.95701...  \n",
       "2  POLYGON ((31.15408 38.61106, 31.15408 38.61600...  \n",
       "3  POLYGON ((-1.60285 38.21084, -1.60285 38.21558...  \n",
       "4  POLYGON ((48.22342 48.99523, 48.22342 49.00099...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7671, 7671, 3221, 5134)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gdf[gdf.has_S2==1]), len(gdf[gdf.has_DEM==1]), len(gdf[gdf.has_S1_ASC==1]), len(gdf[gdf.has_S1_DES==1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and unzip file with eopatches\n",
    "\n",
    "This code downloads and unzips the file containing the `EOPatches`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://queryplanet.sentinel-hub.com/water-labels/eopatches.zip to ./eopatches.zip ..\n",
      "Unzipping ./eopatches.zip to . ..\n"
     ]
    }
   ],
   "source": [
    "print(f'Downloading {EOP_URL} to {EOP_ZIP} ..')\n",
    "with urllib.request.urlopen(EOP_URL) as response, open(EOP_ZIP, 'wb') as zip_file:\n",
    "    shutil.copyfileobj(response, zip_file)\n",
    "    \n",
    "print(f'Unzipping {EOP_ZIP} to {EOP_DIR} ..')\n",
    "with zipfile.ZipFile(EOP_ZIP, 'r') as zip_file:\n",
    "    zip_file.extractall(EOP_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that all `EOPatches` have been downloaded and unzipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7671\r\n"
     ]
    }
   ],
   "source": [
    "ls {EOP_DIR}/eopatches | wc -l "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features preparation\n",
    "\n",
    "This Section pre-processes the dataset into a ML-ready format using `eo-learn`. \n",
    "\n",
    "The workflow is as follows:\n",
    " * load eopatches\n",
    " * extract B02, B03 and B04 from all S2 bands\n",
    " * compute the Normalized Difference Water Index (NDWI)\n",
    " * compute the Normalized Difference Moisture Index (NDMI)\n",
    " * concatenate the features as [B02, B03, B04, NDWI, NDMI]\n",
    " * randomly sample pixels from features and labels\n",
    " * add the newly created features and sampled features to `EOPatches`\n",
    " \n",
    "The workflow is then parallelized over the eopatches for faster execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build name of eopatches, given by index of `data_info`\n",
    "eopatch_names = [f'eopatch-{idx:04d}' for idx in np.arange(len(gdf))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load an `EOPatch` and inspect content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EOPatch(\n",
       "  data: {\n",
       "    BANDS-S2-L1C: numpy.ndarray(shape=(1, 64, 64, 13), dtype=float32)\n",
       "    TRUE-COLOR-S1-IW-DES: numpy.ndarray(shape=(1, 64, 64, 3), dtype=float32)\n",
       "  }\n",
       "  mask: {\n",
       "    IS_DATA: numpy.ndarray(shape=(1, 64, 64, 1), dtype=bool)\n",
       "    IS_DATA_S1_IW_DES: numpy.ndarray(shape=(1, 64, 64, 1), dtype=bool)\n",
       "  }\n",
       "  scalar: {}\n",
       "  label: {}\n",
       "  vector: {}\n",
       "  data_timeless: {\n",
       "    DEM: numpy.ndarray(shape=(64, 64, 1), dtype=float32)\n",
       "  }\n",
       "  mask_timeless: {\n",
       "    water_label: numpy.ndarray(shape=(64, 64, 1), dtype=uint8)\n",
       "  }\n",
       "  scalar_timeless: {}\n",
       "  label_timeless: {}\n",
       "  vector_timeless: {}\n",
       "  meta_info: {\n",
       "    TRUE-COLOR-S1-IW-DES: datetime.timedelta(-2, 6658)\n",
       "    maxcc: 1.0\n",
       "    service_type: 'wms'\n",
       "    size_x: 64\n",
       "    size_y: 64\n",
       "    time_difference: datetime.timedelta(1)\n",
       "    time_interval: (datetime.datetime(2017, 8, 12, 0, 0), datetime.datetime(2017, 8, 13, 0, 0))\n",
       "    timestamp: '2017-08-12'\n",
       "  }\n",
       "  bbox: BBox(((64.47018117599022, 50.951253746594006), (64.47931440474328, 50.9570068827248)), crs=CRS('4326'))\n",
       "  timestamp: [datetime.datetime(2017, 8, 12, 6, 47, 48)]\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eop = EOPatch.load(f'{EOP_DIR}/eopatches/{eopatch_names[1]}')\n",
    "eop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up names of EOPatch features for convenience\n",
    "BANDS_FEATURE = FeatureType.DATA, 'BANDS-S2-L1C'\n",
    "IS_DATA_FEATURE = FeatureType.MASK, 'IS_DATA'\n",
    "\n",
    "BANDS_SUB_FEATURE = FeatureType.DATA, 'BANDS-SUBSET'\n",
    "NDWI_FEATURE = FeatureType.DATA, 'NDWI'\n",
    "NDMI_FEATURE = FeatureType.DATA, 'NDMI'\n",
    "\n",
    "FEATURES = FeatureType.DATA, 'FEATURES'\n",
    "\n",
    "LABELS = FeatureType.MASK_TIMELESS, 'water_label'\n",
    "\n",
    "FEATURES_SAMPLED = FeatureType.DATA, 'FEATURES_SAMPLED'\n",
    "IS_DATA_SAMPLED = FeatureType.MASK, 'IS_DATA_SAMPLED'\n",
    "LABELS_SAMPLED = FeatureType.MASK_TIMELESS, 'water_label_SAMPLED'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise the `EOTask`s defining the workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load eopatch\n",
    "load_task = LoadTask(f'{EOP_DIR}/eopatches/')\n",
    "\n",
    "# Keep only B02, B03, B04\n",
    "extract_task = ExtractBandsTask(input_feature=BANDS_FEATURE, \n",
    "                                output_feature=BANDS_SUB_FEATURE, \n",
    "                                bands=[S2_BANDS.index(s2b) for s2b in ['B02', 'B03', 'B04']])\n",
    "\n",
    "# NDWI = (B03 - B08) / (B03 + B08)\n",
    "ndwi_task = NormalizedDifferenceIndexTask(input_feature=BANDS_FEATURE,\n",
    "                                          output_feature=NDWI_FEATURE,\n",
    "                                          bands=[S2_BANDS.index(s2b) for s2b in ['B03', 'B08']])\n",
    "\n",
    "# NDMI = (B08 - B11) / (B08 + B11)\n",
    "ndmi_task = NormalizedDifferenceIndexTask(input_feature=BANDS_FEATURE,\n",
    "                                          output_feature=NDMI_FEATURE,\n",
    "                                          bands=[S2_BANDS.index(s2b) for s2b in ['B08', 'B11']])\n",
    "\n",
    "# Merge features as [B02, B03, B04, NDWI, NDMI]\n",
    "merge_task = MergeFeatureTask(input_features=[BANDS_SUB_FEATURE, NDWI_FEATURE, NDMI_FEATURE],\n",
    "                              output_feature=FEATURES)\n",
    "\n",
    "# Task for pixels' sampling\n",
    "sampling_task = PointSamplingTask(\n",
    "    n_samples=N_SAMPLES, \n",
    "    ref_mask_feature=LABELS[1], \n",
    "    ref_labels=REF_LABELS, \n",
    "    sample_features=[  # tag fields to sample\n",
    "        FEATURES,\n",
    "        IS_DATA_FEATURE,\n",
    "        LABELS\n",
    "    ])\n",
    "\n",
    "# Add to exising EOPatch only the sampled features and labels\n",
    "save_task = SaveTask(\n",
    "    f'{EOP_DIR}/eopatches/', \n",
    "    features=[FEATURES, FEATURES_SAMPLED, IS_DATA_SAMPLED, LABELS_SAMPLED],\n",
    "    overwrite_permission=OverwritePermission.OVERWRITE_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the workflow\n",
    "workflow = LinearWorkflow(\n",
    "    load_task,\n",
    "    extract_task,\n",
    "    ndwi_task,\n",
    "    ndmi_task,\n",
    "    merge_task,\n",
    "    sampling_task,\n",
    "    save_task\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the workflow in parallel by providing the `execution_args` that include the `on-the-fly` input arguments to the tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bc5cb841ba44b3eb333796cd43b4eca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7671), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1min 46s, sys: 2.63 s, total: 1min 49s\n",
      "Wall time: 3min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Create list of arguments to be passed at run-time\n",
    "execution_args = []\n",
    "for idx, eop_name in enumerate(eopatch_names):\n",
    "    execution_args.append({\n",
    "        load_task: {'eopatch_folder': eop_name},\n",
    "        sampling_task: {'seed': idx},\n",
    "        save_task: {'eopatch_folder': eop_name}\n",
    "    })\n",
    "    \n",
    "# Execute workflow in parallel, e.g. each EOPatch is process in parallel in dedicated processes\n",
    "executor = EOExecutor(workflow, execution_args, save_logs=True)\n",
    "executor.run(workers=N_WORKERS, multiprocess=True)\n",
    "\n",
    "# Make report to check possible failures\n",
    "executor.make_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the same `EOPatch` to check the newly added arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EOPatch(\n",
       "  data: {\n",
       "    BANDS-S2-L1C: numpy.ndarray(shape=(1, 64, 64, 13), dtype=float32)\n",
       "    FEATURES: numpy.ndarray(shape=(1, 64, 64, 5), dtype=float32)\n",
       "    FEATURES_SAMPLED: numpy.ndarray(shape=(1, 100, 1, 5), dtype=float32)\n",
       "    TRUE-COLOR-S1-IW-DES: numpy.ndarray(shape=(1, 64, 64, 3), dtype=float32)\n",
       "  }\n",
       "  mask: {\n",
       "    IS_DATA: numpy.ndarray(shape=(1, 64, 64, 1), dtype=bool)\n",
       "    IS_DATA_S1_IW_DES: numpy.ndarray(shape=(1, 64, 64, 1), dtype=bool)\n",
       "    IS_DATA_SAMPLED: numpy.ndarray(shape=(1, 100, 1, 1), dtype=bool)\n",
       "  }\n",
       "  scalar: {}\n",
       "  label: {}\n",
       "  vector: {}\n",
       "  data_timeless: {\n",
       "    DEM: numpy.ndarray(shape=(64, 64, 1), dtype=float32)\n",
       "  }\n",
       "  mask_timeless: {\n",
       "    water_label: numpy.ndarray(shape=(64, 64, 1), dtype=uint8)\n",
       "    water_label_SAMPLED: numpy.ndarray(shape=(100, 1, 1), dtype=uint8)\n",
       "  }\n",
       "  scalar_timeless: {}\n",
       "  label_timeless: {}\n",
       "  vector_timeless: {}\n",
       "  meta_info: {\n",
       "    TRUE-COLOR-S1-IW-DES: datetime.timedelta(-2, 6658)\n",
       "    maxcc: 1.0\n",
       "    service_type: 'wms'\n",
       "    size_x: 64\n",
       "    size_y: 64\n",
       "    time_difference: datetime.timedelta(1)\n",
       "    time_interval: (datetime.datetime(2017, 8, 12, 0, 0), datetime.datetime(2017, 8, 13, 0, 0))\n",
       "    timestamp: '2017-08-12'\n",
       "  }\n",
       "  bbox: BBox(((64.47018117599022, 50.951253746594006), (64.47931440474328, 50.9570068827248)), crs=CRS('4326'))\n",
       "  timestamp: [datetime.datetime(2017, 8, 12, 6, 47, 48)]\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eop = EOPatch.load(f'{EOP_DIR}/eopatches/{eopatch_names[1]}')\n",
    "eop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train and test sets\n",
    "\n",
    "This section splits the data into a training and a testing set. For optimisation of the model, the training data should be further split to create a cross-validation set, to avoid over-fitting to the test data. \n",
    "\n",
    "The data contained in the `EOPatch`es can belong to the same water-body imaged during the same acquisition time. For this reason, the dataset should be grouped by location and by timestamp, such that data belonging to the same water-body and acquisition time do not end up in different train/test sets.\n",
    "\n",
    "This grouping is here performed first geographically using the centroids of the `BBox`es, and then a further grouping is applied to the timestamps to obtain unique location/timestamp pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf['x']=gdf.geometry.apply(lambda g: g.centroid.x)\n",
    "gdf['y']=gdf.geometry.apply(lambda g: g.centroid.y)\n",
    "\n",
    "db = DBSCAN(eps=0.1, \n",
    "            min_samples=1, \n",
    "            algorithm='ball_tree', \n",
    "            metric='euclidean').fit(gdf[['x', 'y']].to_numpy())\n",
    "\n",
    "# Group by centroid coordinates\n",
    "for label in set(db.labels_):\n",
    "    class_member_mask = (db.labels_ == label)\n",
    "    gdf.loc[class_member_mask,'cluster_id'] = label\n",
    "    \n",
    "# Further group by timestamp\n",
    "gdf['group'] = gdf.groupby(by=['cluster_id','timestamp'],as_index=False).ngroup()\n",
    "gdf.drop(columns=['x','y','cluster_id'], inplace=True)\n",
    "\n",
    "# Randomly assign resulting groups to either train or test set\n",
    "train_ids = set(np.where(np.random.rand(gdf.group.nunique())<=TRAIN_RATIO)[0])\n",
    "gdf['isin_train'] = gdf.group.isin(train_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_DEM</th>\n",
       "      <th>has_S1_ASC</th>\n",
       "      <th>has_S1_DES</th>\n",
       "      <th>has_S2</th>\n",
       "      <th>task_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>window_height</th>\n",
       "      <th>window_width</th>\n",
       "      <th>geometry</th>\n",
       "      <th>group</th>\n",
       "      <th>isin_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6b73fd74a2eb11e994fbf0db728b8d14</td>\n",
       "      <td>2016-09-26</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>POLYGON ((65.84065 52.68916, 65.84065 52.69491...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0a27f4aea2eb11e9bfdaa9140581204c</td>\n",
       "      <td>2017-08-12</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>POLYGON ((64.47018 50.95125, 64.47018 50.95701...</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9b60193ea24111e98d7d929084d604de</td>\n",
       "      <td>2019-03-23</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>POLYGON ((31.15408 38.61106, 31.15408 38.61600...</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9afaabaea24111e983d185262381d01a</td>\n",
       "      <td>2018-05-31</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>POLYGON ((-1.60285 38.21084, -1.60285 38.21558...</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9dfb5254a24111e9a087737fe71fcff1</td>\n",
       "      <td>2018-05-27</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>POLYGON ((48.22342 48.99523, 48.22342 49.00099...</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   has_DEM  has_S1_ASC  has_S1_DES  has_S2                           task_id  \\\n",
       "0        1           0           0       1  6b73fd74a2eb11e994fbf0db728b8d14   \n",
       "1        1           0           1       1  0a27f4aea2eb11e9bfdaa9140581204c   \n",
       "2        1           1           1       1  9b60193ea24111e98d7d929084d604de   \n",
       "3        1           1           1       1  9afaabaea24111e983d185262381d01a   \n",
       "4        1           0           1       1  9dfb5254a24111e9a087737fe71fcff1   \n",
       "\n",
       "    timestamp  window_height  window_width  \\\n",
       "0  2016-09-26             64            64   \n",
       "1  2017-08-12             64            64   \n",
       "2  2019-03-23             64            64   \n",
       "3  2018-05-31             64            64   \n",
       "4  2018-05-27             64            64   \n",
       "\n",
       "                                            geometry  group  isin_train  \n",
       "0  POLYGON ((65.84065 52.68916, 65.84065 52.69491...      1       False  \n",
       "1  POLYGON ((64.47018 50.95125, 64.47018 50.95701...      3        True  \n",
       "2  POLYGON ((31.15408 38.61106, 31.15408 38.61600...      4        True  \n",
       "3  POLYGON ((-1.60285 38.21084, -1.60285 38.21558...      5        True  \n",
       "4  POLYGON ((48.22342 48.99523, 48.22342 49.00099...      7       False  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69ff37b6eae34f519b598dd6d56e09b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7671), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Lazily load sampled eopatches\n",
    "eopatches = []\n",
    "\n",
    "for eopatch_name in tqdm(eopatch_names):\n",
    "    eopatches.append(EOPatch.load(f'{EOP_DIR}/eopatches/{eopatch_name}', lazy_loading=True))    \n",
    "\n",
    "eopatches = np.array(eopatches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the features in `EOPatch` into ML-ready numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the features and the labels for train and test sets\n",
    "features_train = np.array([eopatch[FEATURES_SAMPLED] for eopatch in eopatches[gdf.isin_train.values]])\n",
    "labels_train = np.array([eopatch[LABELS_SAMPLED] for eopatch in eopatches[gdf.isin_train.values]])\n",
    "mask_train = np.array([eopatch[IS_DATA_SAMPLED] for eopatch in eopatches[gdf.isin_train.values]])\n",
    "\n",
    "features_test = np.array([eopatch[FEATURES_SAMPLED] for eopatch in eopatches[~gdf.isin_train.values]])\n",
    "labels_test = np.array([eopatch[LABELS_SAMPLED] for eopatch in eopatches[~gdf.isin_train.values]])\n",
    "mask_test = np.array([eopatch[IS_DATA_SAMPLED] for eopatch in eopatches[~gdf.isin_train.values]])\n",
    "\n",
    "# get shape\n",
    "p1, t, w, h, f = features_train.shape\n",
    "p2, t, w, h, f = features_test.shape\n",
    "p = p1 + p2\n",
    "\n",
    "# reshape to n x m\n",
    "features_train = np.moveaxis(features_train, 1, 3).reshape(p1 * w * h, t * f)\n",
    "labels_train = np.moveaxis(labels_train, 1, 2).reshape(p1 * w * h, 1).squeeze()\n",
    "mask_train = np.moveaxis(mask_train, 1, 2).reshape(p1 * w * h, 1).squeeze()\n",
    "\n",
    "features_test = np.moveaxis(features_test, 1, 3).reshape(p2 * w * h, t * f)\n",
    "labels_test = np.moveaxis(labels_test, 1, 2).reshape(p2 * w * h, 1).squeeze()\n",
    "mask_test = np.moveaxis(mask_test, 1, 2).reshape(p2 * w * h, 1).squeeze()\n",
    "\n",
    "# remove points with no valid data\n",
    "features_train = features_train[mask_train]\n",
    "labels_train = labels_train[mask_train]\n",
    "\n",
    "features_test = features_test[mask_test]\n",
    "labels_test = labels_test[mask_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((610300, 5), (610300,), (156800, 5), (156800,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train.shape, labels_train.shape, features_test.shape, labels_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check class distribution for train and test sets. The `water` labels are roughly in a 2:1 proportion versus the `non-water` labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([0, 1], dtype=uint8), array([218908, 391392])),\n",
       " (array([0, 1], dtype=uint8), array([ 53657, 103143])))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(labels_train, return_counts=True), np.unique(labels_test, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and evaluate model \n",
    "\n",
    "A Gradient-Boosting-Machine algorithm based on decision trees is trained on the features and labels. The number of trees is kept small to reduce the model size. These parameters should be optimised using a subset of the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.58 s, sys: 64.2 ms, total: 2.64 s\n",
      "Wall time: 427 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Set up the model\n",
    "model = lgbm.LGBMClassifier(\n",
    "    objective='binary', \n",
    "    n_estimators=10,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# train the model\n",
    "model.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the test labels\n",
    "plabels_test = model.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy 92.2%\n",
      "Classification F1-score 92.2%\n",
      "\n",
      "             Class              =  F1  | Recall | Precision\n",
      "         --------------------------------------------------\n",
      "         * non-water            = 88.4 |  86.8  | 90.0\n",
      "         * water                = 94.1 |  95.0  | 93.3\n"
     ]
    }
   ],
   "source": [
    "# Compute some performance metrics on the test set\n",
    "pred = plabels_test\n",
    "lbls = labels_test\n",
    "\n",
    "class_labels = REF_LABELS\n",
    "class_names = ['non-water', 'water']\n",
    "\n",
    "f1_scores = metrics.f1_score(lbls, pred, average=None)\n",
    "recall = metrics.recall_score(lbls, pred, average=None)\n",
    "precision = metrics.precision_score(lbls, pred, average=None) \n",
    "\n",
    "print('Classification accuracy {:.1f}%'.format(100 * metrics.accuracy_score(lbls, pred)))\n",
    "print('Classification F1-score {:.1f}%'.format(100 * metrics.f1_score(lbls, pred, average='weighted')))\n",
    "print()\n",
    "print('             Class              =  F1  | Recall | Precision')\n",
    "print('         --------------------------------------------------')\n",
    "for idx, classname in enumerate([class_names[idx] for idx in class_labels]):\n",
    "    print('         * {0:20s} = {1:2.1f} |  {2:2.1f}  | {3:2.1f}'.format(classname, \n",
    "                                                                         f1_scores[idx] * 100, \n",
    "                                                                         recall[idx] * 100, \n",
    "                                                                         precision[idx] * 100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick look at the model's behaviour, checking the feature importance for the features `[B01, B03, B04, NDWI, NDMI]`. The two indices seem to be the most relevant features used by the model. Note that these importance can be misleading, and better indicators for the model's behaviour should be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([54, 63, 13, 79, 91])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert model to evalscript\n",
    "\n",
    "In this Section the trained model is converted to a custom script, using the help functions provided in `lgbm_to_evalscript_utils.py`. Note that the `parse_trees` function is specific for this use-case, and would need to be adapted to other use-cases using different input and output featrues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "js_model = parse_model(model, js_output_filename='water-detection-ML-evalscript.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test evalscript\n",
    "\n",
    "In this part we check that the model prediction and the evalscript return the same results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Possible improvements\n",
    "\n",
    "This notebook showcased a simple workflow to implement a ML-based workflow as a custom-script. \n",
    "\n",
    "Possible improvements for water-detection include:\n",
    "\n",
    " * use of DEM and S1 as input sources\n",
    " * optimise the model\n",
    " * replace the GBM algorithm with other pixel-wise [algorithms](https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
