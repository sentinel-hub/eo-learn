{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Registration transform example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example illustrates how to use a RegistrationTransform to temporally align the frames of an EOPatch using different algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create cloudless timelapse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports from `sentinelhub` and `eolearn` to set up workflow that creates a timelapse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "from sentinelhub import BBox, CRS, MimeType, DataCollection\n",
    "\n",
    "from eolearn.core import EOPatch, FeatureType, LinearWorkflow\n",
    "from eolearn.features import SimpleFilterTask\n",
    "from eolearn.io import SentinelHubInputTask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up BBox of ROI and time interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_bbox = BBox(bbox=[31.112895,29.957240,31.154222,29.987687], crs=CRS.WGS84)\n",
    "# roi_bbox = BBox(bbox=[-6.57257, 37.2732, -5.728, 36.8549], crs=CRS.WGS84)\n",
    "time_interval = ('2018-01-01', '2020-06-01')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This predicate function filters the images with a cloud coverage larger than a threshold to ensure images do not contain cloudy pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxCCPredicate:\n",
    "    def __init__(self, maxcc):\n",
    "        self.maxcc = maxcc\n",
    "\n",
    "    def __call__(self, img_cm):\n",
    "        w, h, _ = img_cm.shape\n",
    "        cc = np.sum(img_cm) / (w * h)\n",
    "        return cc <= self.maxcc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tasks of the workflow:\n",
    " * download S2 images (only 3 bands needed for true color visualitzation)\n",
    " * Download cloud mask (CLM) provided by Sentinel Hub  \n",
    " * filter out images with cloud coverage larger than a given threshold (e.g. 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_task = SentinelHubInputTask(data_collection=DataCollection.SENTINEL2_L1C, \n",
    "                                     bands_feature=(FeatureType.DATA, 'BANDS'),\n",
    "                                     resolution=10, \n",
    "                                     maxcc=0.5, \n",
    "                                     bands=['B02', 'B03', 'B04'], \n",
    "                                     time_difference=datetime.timedelta(hours=2),\n",
    "                                     additional_data=[(FeatureType.MASK, 'dataMask', 'IS_DATA'), (FeatureType.MASK, 'CLM')]\n",
    "                                    )\n",
    "filter_clouds = SimpleFilterTask((FeatureType.MASK, 'CLM'), MaxCCPredicate(maxcc=0.05))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build and execute timelapse as chain of transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "timelapse = LinearWorkflow(download_task, filter_clouds)\n",
    "\n",
    "result = timelapse.execute({\n",
    "    download_task: {\n",
    "        'bbox': roi_bbox,\n",
    "        'time_interval': time_interval\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get result as an eopatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "eopatch_clean = [result[key] for key in result.keys()][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EOPatch(\n",
       "  data: {\n",
       "    BANDS: numpy.ndarray(shape=(130, 331, 404, 3), dtype=float32)\n",
       "  }\n",
       "  mask: {\n",
       "    CLM: numpy.ndarray(shape=(130, 331, 404, 1), dtype=uint8)\n",
       "    IS_DATA: numpy.ndarray(shape=(130, 331, 404, 1), dtype=bool)\n",
       "  }\n",
       "  scalar: {}\n",
       "  label: {}\n",
       "  vector: {}\n",
       "  data_timeless: {}\n",
       "  mask_timeless: {}\n",
       "  scalar_timeless: {}\n",
       "  label_timeless: {}\n",
       "  vector_timeless: {}\n",
       "  meta_info: {\n",
       "    maxcc: 0.5\n",
       "    service_type: 'processing'\n",
       "    size_x: 404\n",
       "    size_y: 331\n",
       "    time_difference: datetime.timedelta(seconds=7200)\n",
       "    time_interval: (datetime.datetime(2018, 1, 1, 0, 0), datetime.datetime(2020, 6, 1, 23, 59, 59))\n",
       "  }\n",
       "  bbox: BBox(((31.112895, 29.95724), (31.154222, 29.987687)), crs=CRS('4326'))\n",
       "  timestamp: [datetime.datetime(2018, 1, 4, 8, 33, 28), ..., datetime.datetime(2020, 5, 28, 8, 41, 58)], length=130\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eopatch_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Help function to create GIFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio, os\n",
    "\n",
    "def make_gif(eopatch, project_dir, filename, fps):\n",
    "    \"\"\"\n",
    "    Generates a GIF animation from an EOPatch.\n",
    "    \"\"\"\n",
    "    with imageio.get_writer(os.path.join(project_dir, filename), mode='I', fps=fps) as writer:\n",
    "            for image in eopatch:\n",
    "                writer.append_data(np.array(np.clip(2.8*image[..., [2, 1, 0]], 0, 255), dtype=np.uint8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write clean EOPatch to GIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_gif(eopatch=eopatch_clean.data['BANDS'] * 255, project_dir='.', filename='eopatch_clean.gif', fps=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run registrations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import registrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eolearn.coregistration import ECCRegistration, ThunderRegistration, PointBasedRegistration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The constructor of the Registration objects takes the attribute type, field name and index of the channel to be used for registration, a dictionary specifying the parameters of the registration, and the interpolation method to be applied to the images. The interpolation methods are (NEAREST, LINEAR and CUBIC). Default is CUBIC. A nearest neighbour interpolation is used on ground-truth data to avoid creation of new labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thunder registration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This algorithm computes translations only between pairs of images, using correlation on the Fourier transforms of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "coregister_thunder = ThunderRegistration((FeatureType.DATA, 'BANDS'), channel=2)\n",
    "\n",
    "eopatch_thunder = coregister_thunder(eopatch_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write result to GIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_gif(eopatch=eopatch_thunder.data['BANDS']*255, project_dir='.', filename='eopatch_thunder.gif', fps=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enhanced Cross-Correlation in OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This algorithm uses intensity values to maximise cross-correlation between pair of images. It uses an Euler transformation (x,y translation plus rotation). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'MaxIters': 200}\n",
    "coregister_ecc = ECCRegistration((FeatureType.DATA, 'BANDS'), channel=2, params=params)\n",
    "\n",
    "eopatch_ecc = coregister_ecc(eopatch_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_gif(eopatch=eopatch_ecc.data['BANDS']*255, project_dir='.', filename='eopatch_ecc.gif', fps=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Point-Based Registration in OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three transformation models are supported for point-based registration, i.e. Euler, PartialAffine and Homography. These methods compute feature descriptors (i.e. SIFT or SURF) of the pair of images to be registered, and estimate a robust transformation using RANSAC to align the matching points. These methods perform poorly compared to the other methods due to the inaccuracies of the feature extraction, point-matching and model fitting. If unplausible transformations are estimated, a warning is issued and an identity matrix is employed instead of the estimated transform. Default parameters are (Model=Euler, Descriptor=SIFT, RANSACThreshold=7.0, MaxIters=1000).\n",
    "\n",
    "Note: In case the following cell will raise an error\n",
    "\n",
    "```Python\n",
    "AttributeError: module 'cv2.cv2' has no attribute 'xfeatures2d'\n",
    "```\n",
    "\n",
    "uninstall and reinstall Python package `opencv-contrib-python`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'Model': 'Euler',\n",
    "    'Descriptor': 'SURF',\n",
    "    'RANSACThreshold': 7.0,\n",
    "    'MaxIters': 1000\n",
    "}\n",
    "\n",
    "coregister_pbased = PointBasedRegistration((FeatureType.DATA, 'BANDS'), channel=2, params=params)\n",
    "\n",
    "eopatch_pbased = coregister_pbased(eopatch_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_gif(eopatch=eopatch_pbased.data['BANDS']*255, project_dir='.', filename='eopatch_pbased.gif', fps=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
